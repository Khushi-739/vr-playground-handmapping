# VR Playground Handmapping: Visionâ€“IMU Based Interactive Virtual Environment for Children

## ðŸ“Œ Project Overview
This project aims to build a lightweight **VR playground experience for children**, using a combination of **smartphone-based VR (Google Cardboard)**, **IMU sensor data**, and **basic hand-tracking using phone camera vision**.  
The user can move their head (IMU rotation), interact with objects in a 3D virtual playground, and see simple responses such as **collisions, sound effects, and object reactions**.  
The system captures a childâ€™s hand in front of the mobile camera, estimates its position using a vision model, maps it into the Unity VR scene, and enables natural interaction with virtual objects.

---

## ðŸŽ¯ Project Objectives

- Build a **Unity-based VR playground** optimized for smartphones (Google Cardboard).
- Integrate **IMU sensor data** to control camera orientation and movement.
- Implement **real-time hand capture** using the phone camera and a simple vision model (e.g., MediaPipe or custom CV).
- Map detected hand coordinates to a **3D virtual hand** inside the VR scene.
- Enable **interaction with virtual objects** through collisions, sounds, and simple animations.
  
---

## ðŸ›  Tech Stack

### Core
- **Unity 3D**
- **C# (Unity scripting)**
- **Google Cardboard XR Plugin / Unity XR Management**
- **Android Build Support**

### Computer Vision
- **MediaPipe Hands** (preferred)  
  or  
- Basic **OpenCV-based hand detection** (Unity WebcamTexture integration)

### Sensors
- Smartphone **IMU (accelerometer + gyroscope)**  
  (Unity Input System / Device Sensors API)

### Version Control
- Git + GitHub repository (shared before Dec 12)

---

## ðŸš€ How to Run the Project

### 1. Clone Repository
```bash
git clone https://github.com/Khushi-739/vr-playground-handmapping
cd vr-playground
```

### 2. Open in Unity
- Install Unity **2021 LTS or higher**
- Open project folder
- Verify Google Cardboard / XR plugins enabled

### 3. Build for Android
- Enable **XR Plugin Management â†’ Cardboard**
- Switch platform to **Android**
- Build APK
- Install APK on Android device
- Insert phone into Google Cardboard viewer

### 4. Using the Demo
- Launch the app  
- Move your head â†’ VR camera rotates (IMU-based)  
- Place hand in front of camera â†’ virtual hand appears  
- Touch playground objects â†’ collision triggers reactions & sounds  

---

## ðŸ‘¥ Contributors

- **Hyunjae Gil** â€” Project Mentor 
- **Sharvari Kamble** â€” ML Integrator, Unity Development, Visionâ€“IMU Interaction Mapping  

---

## ðŸ“… Milestones (High-Level)
1. **Unity Playground Scene Setup**  
   â€“ Basic environment, VR camera rig, object prefabs  
2. **IMU Integration**  
   â€“ Map smartphone rotation + acceleration to VR camera  
3. **Vision Module**  
   â€“ Hand detection â†’ coordinate extraction â†’ smoothing  
4. **Hand-to-VR Mapping**  
   â€“ Visual hand model inside Unity  
5. **Interaction System**  
   â€“ Collisions, sound triggers, basic physics feedback  
6. **Poster Demo Build**  
   â€“ Stable APK + poster figures + video recording  

---

## ðŸ“Ž Repository Roadmap Files
- `README.md` â€“ Project documentation  
- `docs/` â€“ Meeting notes, diagrams (to be added)  


